#!/usr/bin/env python3
"""
OpenFGA + MariaDB Galera é…ç½®æª¢æŸ¥å’Œé©—è­‰å·¥å…·ï¼ˆé›¢ç·šæ¨¡å¼ï¼‰
æ”¯æ´æ²’æœ‰ kubectl æ¬Šé™çš„æƒ…æ³ä¸‹é€²è¡Œé…ç½®é©—è­‰
"""

import json
import yaml
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass


@dataclass
class PodSpec:
    """Pod è¦æ ¼"""
    name: str
    replicas: int
    cpu_request: str
    cpu_limit: str
    memory_request: str
    memory_limit: str
    type: str  # "openfga" or "mariadb"


class OfflineChecker:
    """é›¢ç·šé…ç½®æª¢æŸ¥å·¥å…·"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.config_path = config_path
        self.config = {}
        self.recommendations = []
        
    def load_yaml_config(self, yaml_path: str) -> Dict:
        """è¼‰å…¥ YAML é…ç½®æ–‡ä»¶"""
        try:
            with open(yaml_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"âŒ ç„¡æ³•è¼‰å…¥ YAML: {e}")
            return {}
    
    def load_mock_config(self, json_path: str) -> bool:
        """è¼‰å…¥æ¨¡æ“¬é…ç½®ï¼ˆJSON æ ¼å¼ï¼‰"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            return True
        except FileNotFoundError:
            print(f"âš ï¸  æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {json_path}")
            return False
        except json.JSONDecodeError as e:
            print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼éŒ¯èª¤: {e}")
            return False
    
    def parse_deployment_yaml(self, yaml_path: str) -> List[PodSpec]:
        """è§£æ Deployment YAML ä¸¦æå–è³‡æºé…ç½®"""
        yaml_data = self.load_yaml_config(yaml_path)
        pods = []
        
        if not yaml_data:
            return pods
        
        # è™•ç†å–®å€‹æ–‡ä»¶æˆ–å¤šæ–‡ä»¶ YAML
        docs = yaml_data if isinstance(yaml_data, list) else [yaml_data]
        
        for doc in docs:
            if not doc or doc.get('kind') != 'Deployment':
                continue
            
            metadata = doc.get('metadata', {})
            spec = doc.get('spec', {})
            
            name = metadata.get('name', 'unknown')
            replicas = spec.get('replicas', 1)
            
            # æå–å®¹å™¨è³‡æº
            containers = spec.get('template', {}).get('spec', {}).get('containers', [])
            if not containers:
                continue
            
            container = containers[0]
            resources = container.get('resources', {})
            requests = resources.get('requests', {})
            limits = resources.get('limits', {})
            
            pod_type = "mariadb" if "mariadb" in name.lower() or "galera" in name.lower() else "openfga"
            
            pod = PodSpec(
                name=name,
                replicas=replicas,
                cpu_request=requests.get('cpu', 'N/A'),
                cpu_limit=limits.get('cpu', 'N/A'),
                memory_request=requests.get('memory', 'N/A'),
                memory_limit=limits.get('memory', 'N/A'),
                type=pod_type
            )
            pods.append(pod)
        
        return pods
    
    def check_openfga_config(self, pod: PodSpec) -> Dict:
        """æª¢æŸ¥ OpenFGA é…ç½®æ˜¯å¦ç¬¦åˆè¦ç¯„"""
        issues = []
        recommendations = []
        
        # CPU æª¢æŸ¥ (å»ºè­° 500m-1000m)
        cpu_req = self._parse_cpu(pod.cpu_request)
        if cpu_req and cpu_req < 500:
            issues.append(f"CPU request {pod.cpu_request} éä½ï¼Œå»ºè­°è‡³å°‘ 500m")
        elif cpu_req and cpu_req > 1000:
            recommendations.append(f"CPU request {pod.cpu_request} è¼ƒé«˜ï¼Œç¢ºèªæ˜¯å¦å¿…è¦")
        
        # Memory æª¢æŸ¥ (å»ºè­° 256Mi-512Mi)
        mem_req = self._parse_memory(pod.memory_request)
        if mem_req and mem_req < 256:
            issues.append(f"Memory request {pod.memory_request} éä½ï¼Œå»ºè­°è‡³å°‘ 256Mi")
        elif mem_req and mem_req > 1024:
            recommendations.append(f"Memory request {pod.memory_request} è¼ƒé«˜ï¼Œå¯èƒ½éåº¦é…ç½®")
        
        # å‰¯æœ¬æ•¸æª¢æŸ¥ (å»ºè­° 8-12)
        if pod.replicas < 8:
            issues.append(f"å‰¯æœ¬æ•¸ {pod.replicas} éä½ï¼Œå»ºè­°è‡³å°‘ 8 å€‹ä»¥æ”¯æŒé«˜ RPS")
        elif pod.replicas > 20:
            recommendations.append(f"å‰¯æœ¬æ•¸ {pod.replicas} è¼ƒé«˜ï¼Œç¢ºèªæ˜¯å¦ç¬¦åˆæˆæœ¬é ç®—")
        
        return {
            "pod": pod.name,
            "type": "openfga",
            "issues": issues,
            "recommendations": recommendations,
            "status": "warning" if issues else "ok"
        }
    
    def check_mariadb_config(self, pod: PodSpec) -> Dict:
        """æª¢æŸ¥ MariaDB Galera é…ç½®æ˜¯å¦ç¬¦åˆè¦ç¯„"""
        issues = []
        recommendations = []
        
        # CPU æª¢æŸ¥ (å»ºè­° 1000m-2000m)
        cpu_req = self._parse_cpu(pod.cpu_request)
        if cpu_req and cpu_req < 1000:
            issues.append(f"CPU request {pod.cpu_request} éä½ï¼Œå»ºè­°è‡³å°‘ 1000m (1 core)")
        
        # Memory æª¢æŸ¥ (å»ºè­° 2Gi-4Gi)
        mem_req = self._parse_memory(pod.memory_request)
        if mem_req and mem_req < 2048:
            issues.append(f"Memory request {pod.memory_request} éä½ï¼Œå»ºè­°è‡³å°‘ 2Gi")
        elif mem_req and mem_req > 8192:
            recommendations.append(f"Memory request {pod.memory_request} è¼ƒé«˜ï¼Œç¢ºèªç·©å­˜éœ€æ±‚")
        
        # å‰¯æœ¬æ•¸æª¢æŸ¥ (æ‡‰è©²æ˜¯ 3)
        if pod.replicas != 3:
            issues.append(f"Galera å‰¯æœ¬æ•¸æ‡‰ç‚º 3ï¼Œç›®å‰ç‚º {pod.replicas}")
        
        return {
            "pod": pod.name,
            "type": "mariadb",
            "issues": issues,
            "recommendations": recommendations,
            "status": "warning" if issues else "ok"
        }
    
    def _parse_cpu(self, cpu_str: str) -> Optional[int]:
        """è§£æ CPU å­—ä¸²ç‚º millicores"""
        if cpu_str == 'N/A':
            return None
        
        try:
            if cpu_str.endswith('m'):
                return int(cpu_str[:-1])
            else:
                return int(float(cpu_str) * 1000)
        except (ValueError, AttributeError):
            return None
    
    def _parse_memory(self, mem_str: str) -> Optional[int]:
        """è§£æ Memory å­—ä¸²ç‚º MiB"""
        if mem_str == 'N/A':
            return None
        
        try:
            if mem_str.endswith('Mi'):
                return int(mem_str[:-2])
            elif mem_str.endswith('Gi'):
                return int(float(mem_str[:-2]) * 1024)
            elif mem_str.endswith('M'):
                return int(mem_str[:-1])
            elif mem_str.endswith('G'):
                return int(float(mem_str[:-1]) * 1024)
            else:
                return int(mem_str) // (1024 * 1024)
        except (ValueError, AttributeError):
            return None
    
    def check_connection_pool_config(self, yaml_path: str) -> Dict:
        """æª¢æŸ¥é€£æ¥æ± é…ç½®ï¼ˆå¾ ConfigMap æˆ–ç’°å¢ƒè®Šæ•¸ï¼‰"""
        yaml_data = self.load_yaml_config(yaml_path)
        issues = []
        recommendations = []
        
        if not yaml_data:
            return {"status": "error", "message": "ç„¡æ³•è¼‰å…¥é…ç½®"}
        
        # å°‹æ‰¾ ConfigMap æˆ–ç’°å¢ƒè®Šæ•¸é…ç½®
        docs = yaml_data if isinstance(yaml_data, list) else [yaml_data]
        
        for doc in docs:
            if not doc:
                continue
            
            # æª¢æŸ¥ ConfigMap
            if doc.get('kind') == 'ConfigMap':
                data = doc.get('data', {})
                
                # æª¢æŸ¥é€£æ¥æ± ç›¸é—œé…ç½®
                max_open_conns = data.get('OPENFGA_DATASTORE_MAX_OPEN_CONNS')
                max_idle_conns = data.get('OPENFGA_DATASTORE_MAX_IDLE_CONNS')
                
                if max_open_conns:
                    try:
                        max_open = int(max_open_conns)
                        if max_open < 100:
                            issues.append(f"MAX_OPEN_CONNS={max_open} éä½ï¼Œå»ºè­°è‡³å°‘ 100")
                        elif max_open > 300:
                            recommendations.append(f"MAX_OPEN_CONNS={max_open} è¼ƒé«˜ï¼Œç¢ºèªè³‡æ–™åº«æ‰¿å—èƒ½åŠ›")
                    except ValueError:
                        pass
                
                if max_idle_conns:
                    try:
                        max_idle = int(max_idle_conns)
                        if max_idle < 50:
                            issues.append(f"MAX_IDLE_CONNS={max_idle} éä½ï¼Œå»ºè­°è‡³å°‘ 50")
                    except ValueError:
                        pass
        
        return {
            "status": "ok" if not issues else "warning",
            "issues": issues,
            "recommendations": recommendations
        }
    
    def calculate_total_resources(self, pods: List[PodSpec]) -> Dict:
        """è¨ˆç®—ç¸½è³‡æºéœ€æ±‚"""
        total_cpu = 0
        total_memory = 0
        
        for pod in pods:
            cpu = self._parse_cpu(pod.cpu_request)
            mem = self._parse_memory(pod.memory_request)
            
            if cpu:
                total_cpu += cpu * pod.replicas
            if mem:
                total_memory += mem * pod.replicas
        
        return {
            "total_cpu_millicores": total_cpu,
            "total_cpu_cores": total_cpu / 1000,
            "total_memory_mi": total_memory,
            "total_memory_gi": total_memory / 1024
        }
    
    def print_yaml_analysis(self, yaml_path: str):
        """æ‰“å° YAML åˆ†æå ±å‘Š"""
        print("\n" + "="*80)
        print("ğŸ” OpenFGA éƒ¨ç½²é…ç½®åˆ†æï¼ˆé›¢ç·šæ¨¡å¼ï¼‰")
        print("="*80)
        print(f"\nåˆ†ææ–‡ä»¶: {yaml_path}\n")
        
        # è§£æ YAML
        pods = self.parse_deployment_yaml(yaml_path)
        
        if not pods:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Deployment é…ç½®")
            return
        
        # 1. Pod é…ç½®åˆ†æ
        print("\n[1] Deployment é…ç½®åˆ†æ")
        print("-" * 80)
        
        openfga_pods = [p for p in pods if p.type == "openfga"]
        mariadb_pods = [p for p in pods if p.type == "mariadb"]
        
        print(f"\nOpenFGA Deployments: {len(openfga_pods)}")
        for pod in openfga_pods:
            print(f"\n  ğŸ“¦ {pod.name}")
            print(f"     å‰¯æœ¬æ•¸: {pod.replicas}")
            print(f"     CPU: request={pod.cpu_request}, limit={pod.cpu_limit}")
            print(f"     Memory: request={pod.memory_request}, limit={pod.memory_limit}")
            
            # æª¢æŸ¥é…ç½®
            check_result = self.check_openfga_config(pod)
            if check_result["issues"]:
                print(f"     âš ï¸  å•é¡Œ:")
                for issue in check_result["issues"]:
                    print(f"        - {issue}")
            else:
                print(f"     âœ… é…ç½®ç¬¦åˆè¦ç¯„")
            
            if check_result["recommendations"]:
                print(f"     ğŸ’¡ å»ºè­°:")
                for rec in check_result["recommendations"]:
                    print(f"        - {rec}")
        
        print(f"\n\nMariaDB Galera Deployments: {len(mariadb_pods)}")
        for pod in mariadb_pods:
            print(f"\n  ğŸ—„ï¸  {pod.name}")
            print(f"     å‰¯æœ¬æ•¸: {pod.replicas}")
            print(f"     CPU: request={pod.cpu_request}, limit={pod.cpu_limit}")
            print(f"     Memory: request={pod.memory_request}, limit={pod.memory_limit}")
            
            # æª¢æŸ¥é…ç½®
            check_result = self.check_mariadb_config(pod)
            if check_result["issues"]:
                print(f"     âš ï¸  å•é¡Œ:")
                for issue in check_result["issues"]:
                    print(f"        - {issue}")
            else:
                print(f"     âœ… é…ç½®ç¬¦åˆè¦ç¯„")
            
            if check_result["recommendations"]:
                print(f"     ğŸ’¡ å»ºè­°:")
                for rec in check_result["recommendations"]:
                    print(f"        - {rec}")
        
        # 2. è³‡æºç¸½è¨ˆ
        print("\n\n[2] è³‡æºéœ€æ±‚ç¸½è¨ˆ")
        print("-" * 80)
        
        resources = self.calculate_total_resources(pods)
        print(f"\n  ç¸½ CPU: {resources['total_cpu_cores']:.2f} cores ({resources['total_cpu_millicores']} millicores)")
        print(f"  ç¸½ Memory: {resources['total_memory_gi']:.2f} GiB ({resources['total_memory_mi']} MiB)")
        
        # æª¢æŸ¥æ˜¯å¦è¶³å¤ 
        if resources['total_cpu_cores'] < 10:
            print(f"\n  âš ï¸  ç¸½ CPU å¯èƒ½ä¸è¶³ä»¥æ”¯æ’é«˜ RPSï¼ˆå»ºè­°è‡³å°‘ 10 coresï¼‰")
        else:
            print(f"\n  âœ… CPU è³‡æºå……è¶³")
        
        if resources['total_memory_gi'] < 10:
            print(f"  âš ï¸  ç¸½ Memory å¯èƒ½ä¸è¶³ï¼ˆå»ºè­°è‡³å°‘ 10 GiBï¼‰")
        else:
            print(f"  âœ… Memory è³‡æºå……è¶³")
        
        # 3. é€£æ¥æ± é…ç½®æª¢æŸ¥
        print("\n\n[3] é€£æ¥æ± é…ç½®æª¢æŸ¥")
        print("-" * 80)
        
        pool_check = self.check_connection_pool_config(yaml_path)
        if pool_check["status"] == "ok":
            print("  âœ… é€£æ¥æ± é…ç½®åˆç†")
        elif pool_check["status"] == "warning":
            print("  âš ï¸  é€£æ¥æ± é…ç½®éœ€è¦æ³¨æ„:")
            for issue in pool_check.get("issues", []):
                print(f"     - {issue}")
        
        if pool_check.get("recommendations"):
            print("  ğŸ’¡ å»ºè­°:")
            for rec in pool_check["recommendations"]:
                print(f"     - {rec}")
        
        # 4. é«˜å¯ç”¨æ€§æª¢æŸ¥
        print("\n\n[4] é«˜å¯ç”¨æ€§æª¢æŸ¥")
        print("-" * 80)
        
        ha_checks = []
        
        # OpenFGA å‰¯æœ¬æ•¸
        total_openfga_replicas = sum(p.replicas for p in openfga_pods)
        ha_checks.append(("OpenFGA å‰¯æœ¬æ•¸ â‰¥ 8", total_openfga_replicas >= 8))
        
        # Galera å‰¯æœ¬æ•¸
        total_galera_replicas = sum(p.replicas for p in mariadb_pods)
        ha_checks.append(("Galera å‰¯æœ¬æ•¸ = 3", total_galera_replicas == 3))
        
        # è³‡æºé™åˆ¶è¨­ç½®
        has_limits = all(p.cpu_limit != 'N/A' and p.memory_limit != 'N/A' for p in pods)
        ha_checks.append(("æ‰€æœ‰ Pod è¨­ç½®è³‡æºé™åˆ¶", has_limits))
        
        for check_name, passed in ha_checks:
            status = "âœ…" if passed else "âŒ"
            print(f"  {status} {check_name}")
        
        # ç¸½çµ
        print("\n" + "="*80)
        all_passed = all(passed for _, passed in ha_checks)
        
        if all_passed and total_openfga_replicas >= 8:
            print("âœ… é…ç½®ç¬¦åˆé«˜ RPS è¨­è¨ˆè¦ç¯„ï¼")
            print("\nå»ºè­°çš„ä¸‹ä¸€æ­¥:")
            print("  1. ä½¿ç”¨ kubectl apply éƒ¨ç½²é…ç½®")
            print("  2. ç­‰å¾…æ‰€æœ‰ Pod å°±ç·’")
            print("  3. åŸ·è¡Œç·šä¸Šæª¢æŸ¥: python k8s_deployment_checker.py")
            print("  4. é€²è¡Œæ€§èƒ½æ¸¬è©¦")
        else:
            print("âš ï¸  é…ç½®å°šæœ‰æ”¹é€²ç©ºé–“")
            print("\nå»ºè­°çš„æ“ä½œ:")
            print("  1. æ ¹æ“šä¸Šè¿°å•é¡Œèª¿æ•´ YAML é…ç½®")
            print("  2. ä½¿ç”¨é€£æ¥æ± è¨ˆç®—å™¨: python connection_pool_calculator.py")
            print("  3. é‡æ–°æª¢æŸ¥é…ç½®")
        
        print("="*80 + "\n")
    
    def create_sample_mock_config(self, output_path: str):
        """å‰µå»ºç¯„ä¾‹æ¨¡æ“¬é…ç½®æ–‡ä»¶"""
        sample_config = {
            "namespace": "openfga-prod",
            "pods": [
                {
                    "name": "openfga-server-deployment-abc123",
                    "phase": "Running",
                    "type": "openfga",
                    "cpu": "800m",
                    "memory": "384Mi"
                },
                {
                    "name": "mariadb-galera-0",
                    "phase": "Running",
                    "type": "mariadb",
                    "cpu": "1200m",
                    "memory": "3072Mi"
                },
                {
                    "name": "mariadb-galera-1",
                    "phase": "Running",
                    "type": "mariadb",
                    "cpu": "1100m",
                    "memory": "2968Mi"
                },
                {
                    "name": "mariadb-galera-2",
                    "phase": "Running",
                    "type": "mariadb",
                    "cpu": "1150m",
                    "memory": "3024Mi"
                }
            ],
            "mysql_status": {
                "Threads_connected": 245,
                "Threads_running": 12,
                "Max_used_connections": 287
            },
            "galera_status": {
                "cluster_status": "Primary",
                "cluster_size": 3,
                "local_state": "Synced"
            }
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(sample_config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… å·²å‰µå»ºç¯„ä¾‹é…ç½®: {output_path}")


def main():
    """ä¸»å‡½æ•¸"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     OpenFGA + MariaDB Galera é…ç½®æª¢æŸ¥å·¥å…·ï¼ˆé›¢ç·šæ¨¡å¼ï¼‰                      â•‘
â•‘     ç„¡éœ€ kubectl æ¬Šé™å³å¯é©—è­‰é…ç½®                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("é¸æ“‡æ¨¡å¼:")
    print("  1. åˆ†æ YAML é…ç½®æ–‡ä»¶ï¼ˆæ¨è–¦ï¼‰")
    print("  2. ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šæª¢æŸ¥")
    print("  3. ç”Ÿæˆç¯„ä¾‹æ¨¡æ“¬é…ç½®")
    
    choice = input("\nè«‹é¸æ“‡ (1/2/3): ").strip()
    
    checker = OfflineChecker()
    
    if choice == "1":
        yaml_path = input("\nè«‹è¼¸å…¥ YAML æ–‡ä»¶è·¯å¾‘: ").strip()
        if Path(yaml_path).exists():
            checker.print_yaml_analysis(yaml_path)
        else:
            print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {yaml_path}")
    
    elif choice == "2":
        json_path = input("\nè«‹è¼¸å…¥æ¨¡æ“¬é…ç½® JSON è·¯å¾‘: ").strip()
        if checker.load_mock_config(json_path):
            print("âœ… å·²è¼‰å…¥æ¨¡æ“¬é…ç½®")
            # å¯ä»¥åœ¨é€™è£¡æ·»åŠ é¡å¤–çš„åˆ†æé‚è¼¯
        else:
            print("âŒ ç„¡æ³•è¼‰å…¥é…ç½®")
    
    elif choice == "3":
        output_path = input("\nè«‹è¼¸å…¥è¼¸å‡ºè·¯å¾‘ (é»˜èª mock_config.json): ").strip() or "mock_config.json"
        checker.create_sample_mock_config(output_path)
    
    else:
        print("âŒ ç„¡æ•ˆé¸æ“‡")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nå·²ä¸­æ­¢æª¢æŸ¥ã€‚")
    except Exception as e:
        print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
