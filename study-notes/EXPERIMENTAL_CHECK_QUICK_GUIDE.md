# OpenFGA 實驗性 Check 優化 - 快速概覽

## 核心概念速記

### 傳統 Check 方法
```
決策: 根據關係結構靜態選擇查詢策略
     └─ 三個可用策略: default (慢), weight2 (快), recursive (中速)

執行: 每次都使用相同策略
     └─ 無法根據實際效能調整
```

### 實驗性優化（Planner + Thompson Sampling）
```
決策: 使用貝葉斯學習自動選擇最佳策略
     ├─ 初始: 根據先驗知識猜測
     ├─ 學習: 根據實際執行時間更新信念
     └─ 執行: 選擇期望最佳的策略

效果: 自動發現並持續使用最快的策略
     ├─ 簡單查詢: 無改進（已經很快）
     ├─ 複雜查詢: 10-50% 加速
     └─ 多樣化負載: 自適應優化
```

---

## 三個查詢策略對比

| 策略 | 初始預期 | 效能 | 變異度 | 適用場景 |
|------|---------|------|------|--------|
| **Default** | 50ms | 慢 | 高 | 簡單/通用場景 |
| **Weight2** | 20ms | 快 | 低 | 關係結構適合雙向掃描 |
| **Recursive** | 150ms | 中 | 中 | 遞迴/環形關係 |

---

## Thompson Sampling 工作原理

### 簡化版本

```
第1步: 初始化 (冷啟動)
    └─ 建立三個策略的信念曲線
    └─ 根據先驗（InitialGuess）設定位置

第2步: 決策 (Select)
    ├─ 從三個信念曲線分別採樣
    ├─ "如果我相信 weight2 是 20ms，
    │   default 是 50ms，recursive 是 150ms，
    │   那麼這次執行預期時間分別是多少？"
    └─ 選擇採樣期望最低的策略

第3步: 執行和測量 (UpdateStats)
    ├─ 執行選定策略
    ├─ 記錄實際執行時間（如 18ms）
    └─ 用實際結果更新該策略的信念曲線

第4步: 反覆
    └─ 每次查詢都重複第2-3步
    └─ 信念曲線逐步聚焦到最佳策略
```

### 信念曲線演進示例

```
初始狀態:
Weight2:   [-----20ms-----]  (高信心，窄分佈)
Default:   [----------50ms----------]  (低信心，寬分佈)
Recursive: [----------150ms----------]  (中信心，寬分佈)

第1次執行 (weight2 被選中):
    實際: 18ms ✓ 符合預期
    結果: Weight2 信心進一步提升

第2次執行:
    採樣後，weight2 仍然期望最低
    選擇 weight2，實際 19ms ✓

... 持續執行 ...

穩定狀態:
Weight2:   [20ms]  (非常高信心，超窄分佈)
Default:   [----------50ms----------]  (仍然不太確定)
Recursive: [----------150ms----------]  (仍然不太確定)

結果: 後續查詢幾乎總是選擇 weight2
```

---

## 關鍵參數詳解

### InitialGuess (初始猜測)
**含義**: 演算法對該策略效能的初始假設

```
weight2: 20ms    ← 已驗證快速，信心強
default: 50ms    ← 中等預期，開放心態
recursive: 150ms ← 可能較慢，允許變異
```

### Lambda (λ - 信心度)
**含義**: 相當於"已看到多少次好的執行"

```
λ = 1   ← 完全猜測，易改變（鼓勵探索）
λ = 5   ← 有一定信心，適度調整
λ = 10  ← 很有信心，抗拒改變（鼓勵利用）
```

### Alpha & Beta (α, β - 變異信念)
**含義**: 對該策略執行時間一致性的預期

```
α = 20, β = 2    ← 高精度（執行時間很穩定）
                    例: weight2 總是 20ms 左右
                    策略: 相信並持續使用

α = 0.5, β = 0.5 ← 高不確定（執行時間差異大）
                    例: default 可能 10-100ms
                    策略: 積極探索替代方案

α = 2, β = 2.5   ← 中等變異（允許波動）
                    例: recursive 通常 150ms ±50
                    策略: 平衡利用和探索
```

---

## 實際場景對比

### 場景 1: 簡單直接查詢

```
查詢: document#viewer@user:alice

傳統方法:
    └─ 使用規則判斷，選擇 weight2
    └─ 執行 18ms
    └─ 結果: 穩定 18ms

實驗性優化:
    初始採樣 → 選擇 weight2 → 執行 18ms
    更新信念 → weight2 信心 ↑↑↑
    下次採樣 → 選擇 weight2 → 執行 17ms
    ...
    結果: 穩定 17-18ms，效果相同
    優勢: 自動驗證最佳選擇，無需人工配置
```

### 場景 2: 複雜遞迴查詢

```
查詢: group#member@user:bob (遞迴結構)

傳統方法:
    └─ 使用規則判斷，選擇 recursive
    └─ 執行 150-200ms（有波動）
    └─ 結果: 執行時間波動

實驗性優化:
    初始採樣:
        weight2: 20ms (期望)     ← 嘗試一次
        default: 50ms (期望)     ← 嘗試一次
        recursive: 150ms (期望)  ← 嘗試一次
    
    實驗發現:
        weight2 執行 500ms (失敗!) ❌
        → weight2 信心大幅下降
        
        default 執行 180ms (可以)
        → default 信心小幅上升
        
        recursive 執行 155ms (最快!)
        → recursive 信心提升
    
    逐步學習:
        ~ 10 次查詢後，主要選擇 recursive
        ~ 50 次查詢後，幾乎只選擇 recursive
    
    結果: 執行時間 145-160ms（自動優化）
    優勢: 自動發現最佳策略，無須規則配置
```

### 場景 3: 邊界情況（未知結構）

```
查詢: 新增的複雜關係結構

傳統方法:
    └─ 根據靜態規則猜測
    └─ 可能不是最優選擇
    └─ 無法自動調整
    └─ 結果: 次優效能

實驗性優化:
    初始: 三個策略都在試驗範圍內
    學習: 通過執行逐漸發現最佳策略
    適應: 自動聚焦到最快的選擇
    結果: 無需配置，自動優化到接近最佳
```

---

## 啟用和監控

### 啟用方式

```go
// 設定特性旗標
featureFlagClient.Set(
    serverconfig.ExperimentalCheckOptimizations,
    storeID,
    true  // 啟用
)
```

### 監控指標

```
DispatchCount
    └─ 分派次數
    └─ 低 = 高效策略（weight2）
    └─ 高 = 低效策略（default）

RequestDuration
    └─ 請求耗時
    └─ 應該在啟用前後比較
    └─ 預期: 10-50% 改進（複雜查詢）

CycleDetected
    └─ 環檢測標誌
    └─ 監控是否有異常查詢模式
```

---

## 何時啟用？

### ✅ 建議啟用

- 生產環境，多樣化查詢
- 無法提前優化所有查詢模式
- 效能關鍵系統
- 希望自動調優

### ❌ 不建議啟用

- 單一簡單查詢模式（已優化）
- 記憶體非常受限
- 需要確定性執行時間
- 冷啟動期間要求峰值效能

---

## 記憶體考量

### 預設行為
```
計畫永不驅逐 (EvictionThreshold = 0)
└─ 優勢: 持續學習，最優化
└─ 劣勢: 無限增長（不同的查詢鍵）
```

### 配置驅逐
```go
planner.New(&planner.Config{
    EvictionThreshold: 30 * time.Minute,  // 30分鐘未使用則驅逐
    CleanupInterval:   5 * time.Minute,   // 每5分鐘檢查一次
})
```

---

## 故障排除

| 現象 | 原因 | 解決方案 |
|------|------|--------|
| 某些查詢變慢 | Planner 在探索期選了不好的策略 | 等待學習收斂 |
| 記憶體持續增長 | 計畫數無限增加 | 設定驅逐阈值 |
| 效能波動大 | 系統負載波動影響學習 | 增加信心參數 (Lambda, Alpha) |
| 沒看到效能改進 | 查詢模式單純，已最優 | 檢查是否啟用，或查詢已很快 |

---

## 代碼位置速查

| 功能 | 檔案 |
|------|------|
| Planner 主體 | `internal/planner/planner.go` |
| Thompson Sampling | `internal/planner/thompson.go` |
| Check 策略選擇 | `internal/graph/check.go` (checkDirectUsersetTuples) |
| Weight2 實現 | `internal/graph/weight_two_resolver.go` |
| Recursive 實現 | `internal/graph/recursive_resolver.go` |
| Default 實現 | `internal/graph/default_resolver.go` |
| 特性旗標 | `pkg/server/check.go` (WithOptimizations) |

---

## 文獻參考

**Thompson Sampling** 是一個經典的線上學習算法，已被廣泛應用於：
- A/B 測試
- 廣告推薦
- 資源分配優化

OpenFGA 將其應用於**查詢策略選擇**，這是一個創新的使用案例。

---

## 總結

| 層面 | 傳統方法 | 實驗性優化 |
|------|--------|---------|
| **配置複雜性** | 低 | 低（預設可用） |
| **效能優化** | 靜態 | 動態自適應 |
| **複雜查詢** | 效能固定 | 自動優化 |
| **記憶體開銷** | 無 | 中等 |
| **效能改進** | 無 | 10-50% |
| **推薦場景** | 單純查詢 | 多樣化負載 |
